{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Практическая работа №6.\n",
        "### Выполнил: Росляков Владислав Александрович\n",
        "### Группа: ББМО-01-23"
      ],
      "metadata": {
        "id": "VEXf1co874rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 1. Создание полносвязной нейронной сети и сверточной нейронной сети."
      ],
      "metadata": {
        "id": "1jzwUlIB-5Cd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2c-xNXZ7q4l",
        "outputId": "fc8acf1c-6131-4573-b1b8-19c0384b0b0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.4388\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9657 - loss: 0.1201\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.0766\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.0578\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.0424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 23ms/step - accuracy: 0.9098 - loss: 0.2980\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.9827 - loss: 0.0569\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.9902 - loss: 0.0325\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 22ms/step - accuracy: 0.9931 - loss: 0.0210\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.9950 - loss: 0.0150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# Загрузка данных MNIST\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# Нормализация данных\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "# Преобразование меток в one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "# Модель 1: Простая полносвязная нейронная сеть\n",
        "model1 = Sequential([\n",
        "  Flatten(input_shape=(28, 28)),\n",
        "  Dense(128, activation='relu'),\n",
        "  Dense(10, activation='softmax')])\n",
        "# Компиляция модели\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n",
        "# Обучение модели\n",
        "model1.fit(train_images, train_labels, epochs=5)\n",
        "# Сохранение модели\n",
        "model1.save('mnist_model.h5')\n",
        "# Модель 2: Свёрточная нейронная сеть (CNN)\n",
        "model2 = Sequential([\n",
        "  Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D((2, 2)),\n",
        "  Flatten(),\n",
        "  Dense(128, activation='relu'),\n",
        "  Dense(10, activation='softmax')\n",
        "])\n",
        "# Компиляция модели\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n",
        "# Обучение модели\n",
        "model2.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=5)\n",
        "# Сохранение модели\n",
        "model2.save('mnist_model_2.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 2. Реализуем атаку FGSM на первую модель"
      ],
      "metadata": {
        "id": "ktk2m6m9_Hae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Функция для реализации FGSM атаки\n",
        "def fgsm_attack(image, epsilon, gradient):\n",
        "  # Применение знака градиента к изображению\n",
        "  perturbed_image = image + epsilon * np.sign(gradient)\n",
        "  # Обрезка значений, чтобы они оставались в пределах [0,1]\n",
        "  perturbed_image = np.clip(perturbed_image, 0, 1)\n",
        "  return perturbed_image\n",
        "# Вычисление градиента\n",
        "def generate_adversarial_example(model, image, label, epsilon):\n",
        "    # Превращаем изображение в формат, подходящий для модели\n",
        "    image = tf.convert_to_tensor(image.reshape((1, 28, 28, 1)))\n",
        "\n",
        "    # Если label — это one-hot вектор, преобразуем его в индекс\n",
        "    if len(label.shape) > 1 and label.shape[1] > 1:\n",
        "        label = np.argmax(label)\n",
        "    label = tf.convert_to_tensor(label)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(image)\n",
        "        prediction = model(image)\n",
        "        loss = tf.keras.losses.categorical_crossentropy(label[None], prediction)\n",
        "\n",
        "    gradient = tape.gradient(loss, image)\n",
        "\n",
        "    # Применяем FGSM\n",
        "    adversarial_image = fgsm_attack(image.numpy(), epsilon, gradient.numpy())\n",
        "\n",
        "    # Убедимся, что adversarial_image имеет правильную форму\n",
        "    return np.reshape(adversarial_image, (28, 28, 1))\n",
        "\n",
        "def generate_adversarial_dataset(model, images, labels, epsilon):\n",
        "    adversarial_images = []\n",
        "    for i in range(len(images)):\n",
        "        adv_image = generate_adversarial_example(model, images[i], labels[i], epsilon)\n",
        "        adversarial_images.append(adv_image.reshape(28, 28))\n",
        "\n",
        "    adversarial_images = np.array(adversarial_images)\n",
        "\n",
        "    # Проверка формы\n",
        "    print(\"Shape of adversarial_images:\", adversarial_images.shape)\n",
        "\n",
        "    return adversarial_images\n",
        "\n",
        "\n",
        "# Генерация противоречивых примеров для первой модели\n",
        "epsilon = 0.1\n",
        "adversarial_images_model1 = generate_adversarial_dataset(model1, test_images, test_labels, epsilon)"
      ],
      "metadata": {
        "id": "5jShQ2zG_ZD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c0539a-f265-4cb5-f8e0-b7cd9f231190"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of adversarial_images: (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 3. Оценка противоречивых примеров на обеих моделях"
      ],
      "metadata": {
        "id": "R60NgCMAAn9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка первой модели на противоречивых примерах\n",
        "loss1, acc1 = model1.evaluate(adversarial_images_model1, test_labels)\n",
        "print(f'Accuracy of model1 on adversarial examples: {acc1}')\n",
        "\n",
        "# Оценка второй модели на противоречивых примерах (перенос атаки)\n",
        "adversarial_images_model1_reshaped = adversarial_images_model1.reshape(-1, 28, 28, 1)\n",
        "loss2, acc2 = model2.evaluate(adversarial_images_model1_reshaped, test_labels)\n",
        "print(f'Accuracy of model2 on adversarial examples from model1: {acc2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQw8PrguAr6s",
        "outputId": "95f1641a-1dce-421a-de33-56a0c27a3045"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0801 - loss: 6.6760\n",
            "Accuracy of model1 on adversarial examples: 0.10119999945163727\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9534 - loss: 0.1478\n",
            "Accuracy of model2 on adversarial examples from model1: 0.9628999829292297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 4: Анализ переносимости атак"
      ],
      "metadata": {
        "id": "fuTyrAYXA3F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_images_model2 = generate_adversarial_dataset(model2,\n",
        "test_images.reshape(-1, 28, 28, 1), test_labels, epsilon)\n",
        "\n",
        "# Оценка первой модели на противоречивых примерах второй модели\n",
        "loss3, acc3 = model1.evaluate(adversarial_images_model2.reshape(-1, 28,\n",
        "28), test_labels)\n",
        "print(f'Accuracy of model1 on adversarial examples from model2: {acc3}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq-a3ZcFA316",
        "outputId": "71fe122d-bb8c-44be-f7d0-75b7439550e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of adversarial_images: (10000, 28, 28)\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9248 - loss: 0.2604\n",
            "Accuracy of model1 on adversarial examples from model2: 0.9352999925613403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вывод: Исследована атака по переносу с использованием FGSM. Примеры для модели 1 снизили её точность с 98% до 10%, тогда как у модели 2 точность упала лишь на 3-4%. Примеры модели 2 вызвали снижение точности модели 1 на 5%. Атака сильнее влияет на модель, для которой создавались примеры, что подчёркивает важность повышения её устойчивости."
      ],
      "metadata": {
        "id": "nUpO_06QBtYC"
      }
    }
  ]
}